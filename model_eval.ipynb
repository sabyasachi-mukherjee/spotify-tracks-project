{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotify.data_transformations import DataTransformations\n",
    "from spotify.train_test_split import DatasetSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/home/sabyasachi/git/spotify_tracks/dataset/tracks.csv\"\n",
    ")  # Read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = (df\n",
    ".pipe(DataTransformations.preprocess)\n",
    ".pipe(DataTransformations.process)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279704</th>\n",
       "      <td>0</td>\n",
       "      <td>147840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.859</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.520</td>\n",
       "      <td>124.948</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93413</th>\n",
       "      <td>0</td>\n",
       "      <td>245227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.561</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.496</td>\n",
       "      <td>153.030</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218976</th>\n",
       "      <td>0</td>\n",
       "      <td>257827</td>\n",
       "      <td>0</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.557</td>\n",
       "      <td>102.060</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470829</th>\n",
       "      <td>0</td>\n",
       "      <td>218205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.628</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.310</td>\n",
       "      <td>121.218</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380728</th>\n",
       "      <td>0</td>\n",
       "      <td>228160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.645</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.664</td>\n",
       "      <td>164.039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity  duration_ms explicit  danceability  energy key  loudness  \\\n",
       "279704          0       147840        0         0.733   0.859   9    -5.030   \n",
       "93413           0       245227        0         0.497   0.730   1    -4.561   \n",
       "218976          0       257827        0         0.699   0.710   0    -5.525   \n",
       "470829          0       218205        0         0.786   0.628   4    -6.226   \n",
       "380728          0       228160        0         0.518   0.645   4    -5.579   \n",
       "\n",
       "       mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "279704    0       0.0330        0.4790          0.064500    0.1050    0.520   \n",
       "93413     0       0.0573        0.5910          0.000001    0.1900    0.496   \n",
       "218976    0       0.0295        0.0588          0.000000    0.1340    0.557   \n",
       "470829    0       0.0694        0.0113          0.005510    0.0676    0.310   \n",
       "380728    0       0.0329        0.5290          0.000814    0.1770    0.664   \n",
       "\n",
       "          tempo time_signature  \n",
       "279704  124.948              4  \n",
       "93413   153.030              4  \n",
       "218976  102.060              4  \n",
       "470829  121.218              4  \n",
       "380728  164.039              4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lengths of the train and test sets are 84941 and 21236 respectively.\n"
     ]
    }
   ],
   "source": [
    "train_set = DatasetSplit.return_train(DF)\n",
    "test_set = DatasetSplit.return_test(DF)\n",
    "print(\"The lengths of the train and test sets are {} and {} respectively.\".format(len(train_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, t_test split\n",
    "X_train = train_set.copy().drop(columns=['popularity'])\n",
    "y_train = train_set['popularity']\n",
    "X_test = test_set.copy().drop(columns=['popularity'])\n",
    "y_test = test_set['popularity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_array = y_train.to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8919720747342272\n",
      "The precision score is 0.0.\n",
      "The recall score is 0.0.\n",
      "The AUC score is 0.5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/sabyasachi/abc3d35f-a5e6-4ca6-9ec4-719bb77b1459/sabyasachi/git/spotify-tracks-project/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_train_pred = dummy_clf.predict(X_train)\n",
    "print(dummy_clf.score(X_train, y_train))\n",
    "\n",
    "# precision, recall\n",
    "print(f\"The precision score is {precision_score(dummy_train_pred, y_train)}.\")\n",
    "\n",
    "print(f\"The recall score is {recall_score(dummy_train_pred, y_train)}.\")\n",
    "print(f\"The AUC score is {roc_auc_score(y_train, dummy_train_pred)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936426460719794\n",
      "The precision score is 0.9439843068875327.\n",
      "The recall score is 0.9970073664825047.\n",
      "The AUC score is 0.9718205702589184.\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_clf = tree.DecisionTreeClassifier()\n",
    "decision_clf.fit(X_train, y_train)\n",
    "decision_train_pred = decision_clf.predict(X_train)\n",
    "print(decision_clf.score(X_train, y_train))\n",
    "\n",
    "# precision, recall, roc score\n",
    "print(f\"The precision score is {precision_score(decision_train_pred, y_train)}.\")\n",
    "print(f\"The recall score is {recall_score(decision_train_pred, y_train)}.\")\n",
    "print(f\"The AUC score is {roc_auc_score(y_train, decision_train_pred)}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8919720747342272\n",
      "The precision score is 0.0.\n",
      "The recall score is 0.0.\n",
      "The AUC score is 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/sabyasachi/abc3d35f-a5e6-4ca6-9ec4-719bb77b1459/sabyasachi/git/spotify-tracks-project/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_clf = LogisticRegression(random_state=0)\n",
    "logistic_clf.fit(X_train, y_train)\n",
    "logistic_train_pred = logistic_clf.predict(X_train)\n",
    "print(logistic_clf.score(X_train, y_train))\n",
    "\n",
    "# precision, recall\n",
    "print(f\"The precision score is {precision_score(logistic_train_pred, y_train)}.\")\n",
    "print(f\"The recall score is {recall_score(logistic_train_pred, y_train)}.\")\n",
    "print(f\"The AUC score is {roc_auc_score(y_train, logistic_train_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96882541999741\n",
      "The precision score is 0.9845248474280732.\n",
      "The recall score is 0.782842287694974.\n",
      "The AUC score is 0.9757244444360059\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "random_clf = RandomForestClassifier(max_depth=20, random_state=0, class_weight= \"balanced\")\n",
    "random_clf.fit(X_train, y_train)\n",
    "random_train_pred = random_clf.predict(X_train)\n",
    "print(random_clf.score(X_train, y_train))\n",
    "\n",
    "print(f\"The precision score is {precision_score(random_train_pred, y_train)}.\")\n",
    "print(f\"The recall score is {recall_score(random_train_pred, y_train)}.\")\n",
    "print(f\"The AUC score is {roc_auc_score(y_train, random_train_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8145601808250141\n",
      "The precision score is 0.22421908429610612.\n",
      "The recall score is 0.1978104945262363.\n",
      "The AUC score is 0.5558896363329305.\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_test_pred = decision_clf.predict(X_test)\n",
    "print(decision_clf.score(X_test, y_test))\n",
    "\n",
    "# precision, recall, roc score\n",
    "print(f\"The precision score is {precision_score(decision_test_pred, y_test)}.\")\n",
    "print(f\"The recall score is {recall_score(decision_test_pred, y_test)}.\")\n",
    "print(f\"The AUC score is {roc_auc_score(y_test, decision_test_pred)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889951026558674\n",
      "The precision score is 0.0.\n",
      "The recall score is 0.0.\n",
      "The AUC score is 0.5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/sabyasachi/abc3d35f-a5e6-4ca6-9ec4-719bb77b1459/sabyasachi/git/spotify-tracks-project/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_test_pred = logistic_clf.predict(X_test)\n",
    "print(logistic_clf.score(X_test, y_test))\n",
    "\n",
    "# precision, recall, roc score\n",
    "print(f\"The precision score is {precision_score(logistic_test_pred, y_test)}.\")\n",
    "print(f\"The recall score is {recall_score(logistic_test_pred, y_test)}.\")\n",
    "print(f\"The AUC score is {roc_auc_score(y_test, logistic_test_pred)}.\") # Nothing suprising about the precision, recall and AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8593426257298926\n",
      "The precision score is 0.2173727000427899.\n",
      "The recall score is 0.304921968787515.\n",
      "The AUC score is 0.5780498084054364.\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "random_test_pred = random_clf.predict(X_test)\n",
    "print(random_clf.score(X_test, y_test))\n",
    "\n",
    "# precision, recall, roc score\n",
    "print(f\"The precision score is {precision_score(random_test_pred, y_test)}.\")\n",
    "print(f\"The recall score is {recall_score(random_test_pred, y_test)}.\")\n",
    "print(f\"The AUC score is {roc_auc_score(y_test, random_test_pred)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the precision and recall scores, and the AUC score, we should go with random forests. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c651e244ac1d95d29a8e67b44fdda86067bb5c36d97f1974fa9ddace7e61c4fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
